{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odshr4rHCRsF"
   },
   "source": [
    "## Download needed dataset and pacakge\n",
    "> Wandb should login first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSghz4yLBjYO",
    "outputId": "e16d37ea-1270-422f-cda9-2864dd57251e"
   },
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "!gdown --id 1iXIqmmQWQO5owW03ZOGIi7fdLCjAe4SI --output CelebA\n",
    "!gdown --id 1bfW4ljiLRQKLdUo68-qqRtxHFU_u4VJK\n",
    "!unzip -q CelebA\n",
    "!wget https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_frontalface_alt.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iDHQnHRuhh7N",
    "outputId": "4144798a-4646-40ba-9885-c548a2470b53"
   },
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pYHzQJNo9ZMs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3f8w91Uq_zW8"
   },
   "source": [
    "## Create model\n",
    "The model architecture is refered to [here](https://github.com/sthalles/SimCLR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XdV4rVeD-qxx"
   },
   "outputs": [],
   "source": [
    "class SimCLRModel(nn.Module):\n",
    "    def __init__(self, model_type=\"resnet18\", \n",
    "                 pretrained=False, out_dim=128):\n",
    "        super().__init__()\n",
    "\n",
    "        # Create model\n",
    "        if pretrained == False:\n",
    "            self.model = getattr(models, \"resnet18\")(\n",
    "                num_classes=out_dim\n",
    "            )\n",
    "        else:\n",
    "            self.model = getattr(models, \"resnet18\")(\n",
    "                pretrained=True\n",
    "            )\n",
    "\n",
    "        dim_mlp = self.model.fc.in_features\n",
    "\n",
    "        # Add projection head\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(dim_mlp, out_dim),\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.Linear(out_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjGsUMJfAIay"
   },
   "source": [
    "## Create Dataset and Data-Aug\n",
    "* RandomHorizontalFlip\n",
    "* RandomResizedCrop\n",
    "* Gaussian Blur\n",
    "* Color Jitter\n",
    "* RandomGrayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "necYj_7K_9hZ"
   },
   "outputs": [],
   "source": [
    "class CelebADataset(Dataset):\n",
    "    def __init__(self, csv_path=\"celebA.csv\", \n",
    "                 img_root=\"img_align_celeba\", size=32):\n",
    "        self.img_root = img_root\n",
    "        self.csv = pd.read_csv(csv_path, index_col=0)\n",
    "        self.face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "        color_jitter = transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.RandomResizedCrop(size=size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomApply([color_jitter], p=0.8),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.GaussianBlur(kernel_size=int(0.1 * size)),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Read in image\n",
    "        img_path = os.path.join(self.img_root, str(self.csv.iloc[idx, 0]))\n",
    "        img = cv2.imread(img_path)\n",
    "        # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # # Crop the faces only\n",
    "        # x, y, w, h = self.face_cascade.detectMultiScale(gray, 1.3, 4)[0]\n",
    "        # img = cv2.cvtColor(img[y:y+h, x:x+w], cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Transformation\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_one = self.transforms(img)\n",
    "        img_two = self.transforms(img)\n",
    "\n",
    "        return img_one, img_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZTQTpHEJi2K"
   },
   "outputs": [],
   "source": [
    "def make_loader(batch_size):\n",
    "    dataset = CelebADataset()\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset, batch_size=batch_size, shuffle=True,\n",
    "        drop_last=True, pin_memory=True\n",
    "    )\n",
    "\n",
    "    return dataset, dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GWb2-L3aYe6"
   },
   "source": [
    "## Visualizing tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zsaagg1TfjQ7"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def plot_points(model, img_root=\"img_align_celeba\", num_points=10):\n",
    "    model.eval()\n",
    "    \n",
    "    # Choose points\n",
    "    dirs = os.listdir(img_root)\n",
    "    plot_image_list = random.choices(dirs, k=num_points)\n",
    "    base_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(32)\n",
    "    ])\n",
    "\n",
    "    # Get features from the list\n",
    "    features_list = []\n",
    "    for img_name in plot_image_list:\n",
    "        img = Image.open(os.path.join(img_root, img_name))\n",
    "        img = base_transform(img).unsqueeze(0).to(config.device)\n",
    "        features = features_list.append(model(img).cpu()[0].tolist())\n",
    "\n",
    "    # Do the dimension reduction\n",
    "    two_dim_pca = PCA(n_components=2).fit_transform(features_list)\n",
    "    two_dim_tsne = TSNE(n_components=2).fit_transform(features_list)\n",
    "\n",
    "    # Show plot\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.set_title(\"PCA\")\n",
    "    ax1.scatter(two_dim_pca[:, 0], two_dim_pca[:, 1], c=list(range(num_points)))\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.set_title(\"TSNE\")\n",
    "    ax2.scatter(two_dim_tsne[:, 0], two_dim_tsne[:, 1], c=list(range(num_points)))\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1IwsQNFT6In"
   },
   "source": [
    "## Create main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kcfsm8P3T5kN"
   },
   "outputs": [],
   "source": [
    "class SimCLR:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        _, self.train_loader = make_loader(batch_size=args.batch_size)\n",
    "        self.model = SimCLRModel(args.model_type, args.pretrained, args.out_dim).to(self.args.device)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss().to(self.args.device)\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.model.parameters(), args.lr, weight_decay=args.weight_decay\n",
    "        )\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            self.optimizer, T_max=len(self.train_loader), eta_min=0, last_epoch=-1\n",
    "        )\n",
    "        os.makedirs(\"weight\", exist_ok=True)\n",
    "\n",
    "\n",
    "    def info_nce_loss(self, features):\n",
    "        labels = torch.cat([torch.arange(self.args.batch_size) for i in range(self.args.n_views)], dim=0)\n",
    "        labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "        labels = labels.to(self.args.device)\n",
    "\n",
    "        features = F.normalize(features, dim=1)\n",
    "\n",
    "        similarity_matrix = torch.matmul(features, features.T)\n",
    "\n",
    "        # Discard the main diagonal from both: labels and similarities matrix\n",
    "        mask = torch.eye(labels.shape[0], dtype=torch.bool).to(self.args.device)\n",
    "        labels = labels[~mask].view(labels.shape[0], -1)\n",
    "        similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "\n",
    "        # Select and combine multiple positives\n",
    "        positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
    "\n",
    "        # Select only the negatives the negatives\n",
    "        negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
    "\n",
    "        logits = torch.cat([positives, negatives], dim=1)\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).to(self.args.device)\n",
    "\n",
    "        logits = logits / self.args.temperature\n",
    "        return logits, labels\n",
    "\n",
    "    def train(self,):\n",
    "        model_config = {\n",
    "            \"batch_size\": self.args.batch_size,\n",
    "            \"epochs\": self.args.epochs,\n",
    "            \"learning rate\": self.args.lr,\n",
    "            \"temerature\": self.args.temperature\n",
    "        }\n",
    "\n",
    "        run = wandb.init(\n",
    "            project=\"facial_identity\",\n",
    "            resume=False,\n",
    "            config=model_config,\n",
    "        )\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "        scaler = GradScaler(enabled=self.args.fp16_precision)\n",
    "\n",
    "        for epoch in range(self.args.epochs):\n",
    "            tqdm_iter = tqdm(\n",
    "                self.train_loader,\n",
    "                bar_format=\"{l_bar}|{bar}| {n_fmt}/{total_fmt} [{rate_fmt}{postfix}|{elapsed}<{remaining}]\",\n",
    "            )\n",
    "\n",
    "            epoch_loss = 0.0\n",
    "            for images in tqdm_iter:\n",
    "                images = torch.cat(images, dim=0)\n",
    "\n",
    "                images = images.to(self.args.device)\n",
    "\n",
    "                with autocast(enabled=self.args.fp16_precision):\n",
    "                    features = self.model(images)\n",
    "                    logits, labels = self.info_nce_loss(features)\n",
    "                    loss = self.criterion(logits, labels)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                scaler.step(self.optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                tqdm_iter.set_description(f\"Epoch: {epoch + 1}\")\n",
    "                tqdm_iter.set_postfix_str(f\"loss={loss.item():^7.3f}\")\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            log = {\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"loss\": epoch_loss / len(tqdm_iter),\n",
    "                \"Image\": plot_points(self.model, num_points=1000) \n",
    "            }\n",
    "            wandb.log(log)\n",
    "\n",
    "            # Save the model every 5 epochs\n",
    "            if epoch % 5 == 0:\n",
    "                torch.save(self.model.state_dict(), f\"weight/model_{epoch + 1}.pt\")\n",
    "\n",
    "            # Warmup for the first 10 epochs\n",
    "            if epoch >= 10:\n",
    "                self.scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpePz1ELWMZF"
   },
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tzMS6Hy4WL9D"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Model settings\n",
    "    model_type = \"resnet18\"\n",
    "    out_dim = 128\n",
    "    pretrained = False\n",
    "\n",
    "    # Training device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Hyper parameters\n",
    "    epochs = 100\n",
    "    batch_size = 1024\n",
    "    lr = 3e-4\n",
    "    weight_decay = 1e-4\n",
    "    fp16_precision = True\n",
    "    temperature = 0.7\n",
    "    n_views = 2\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8AXtWdYWJaq"
   },
   "outputs": [],
   "source": [
    "simclr = SimCLR(args=config)\n",
    "simclr.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWVS9hwqOTv2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "facial_identity",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
